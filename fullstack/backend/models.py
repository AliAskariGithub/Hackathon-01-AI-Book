"""Data models for RAG pipeline and conversational AI agent."""

from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Optional, Dict
import uuid


# =============================================================================
# Spec-2: Agent Exception Classes (T010)
# =============================================================================

class AgentError(Exception):
    """Base exception for agent errors."""
    pass


class RetrievalError(AgentError):
    """Error during vector search."""
    pass


class GenerationError(AgentError):
    """Error during LLM response generation."""
    pass


class ContextOverflowError(AgentError):
    """Context exceeds token budget."""
    pass


class ConfigurationError(AgentError):
    """Invalid agent configuration."""
    pass


# =============================================================================
# Spec-1: Existing Data Models
# =============================================================================


@dataclass
class ContentPage:
    """Represents a scraped page from the Docusaurus book."""
    url: str
    title: str
    raw_content: str
    scraped_at: datetime = field(default_factory=datetime.now)


@dataclass
class ContentChunk:
    """Represents a chunked segment of page content."""
    id: str
    content_hash: str
    text: str
    token_count: int
    chunk_index: int
    page_url: str
    page_title: str


@dataclass
class VectorEmbedding:
    """Represents the numerical vector generated by Cohere API."""
    chunk_id: str
    vector: List[float]
    model: str
    input_type: str
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class QdrantCollection:
    """Represents the vector collection configuration."""
    name: str
    vector_size: int = 1024
    distance: str = "Cosine"


@dataclass
class RetrievalResult:
    """Represents a query result returned from semantic search."""
    chunk_id: str
    text: str
    score: float
    url: str
    title: str
    chunk_index: int


@dataclass
class QueryResult:
    """Represents the result of a single validation query."""
    query: str
    top_score: float
    passed: bool
    top_results: List[RetrievalResult] = field(default_factory=list)


@dataclass
class ValidationReport:
    """Represents the outcome of pipeline validation."""
    timestamp: datetime
    total_queries: int
    passed_queries: int
    failed_queries: int
    pass_rate: float
    threshold: float
    avg_similarity: float
    results: List[QueryResult] = field(default_factory=list)


@dataclass
class IngestionResult:
    """Represents the result of a book ingestion run."""
    success: bool
    pages_discovered: int
    pages_scraped: int
    chunks_created: int
    embeddings_generated: int
    vectors_stored: int
    duplicates_skipped: int
    errors: List[str] = field(default_factory=list)
    duration_seconds: float = 0.0


# =============================================================================
# Spec-2: Agent Data Models (T011-T017)
# =============================================================================

# System prompt for the RAG agent
DEFAULT_SYSTEM_PROMPT = """You are an AI assistant for the Isaac Sim Robotics book. Your role is to help users find information from the book content.

IMPORTANT RULES:
1. Answer questions using ONLY the provided context from the book
2. Always cite your sources using this exact format: [Source: Title](URL)
3. If the context doesn't contain relevant information, say: "I don't have information about that in the book content."
4. Do not answer questions outside the scope of robotics, Isaac Sim, and related topics covered in the book
5. Be concise but thorough in your answers
6. If multiple sources are relevant, cite all of them

Example citation format:
"URDF is a format for describing robots [Source: URDF Basics](https://example.com/urdf)."
"""


@dataclass
class Citation:
    """Represents a source reference within a message (T011)."""
    title: str
    url: str
    score: float = 0.0
    excerpt: str = ""
    chunk_id: str = ""

    def __str__(self) -> str:
        return f"[Source: {self.title}]({self.url})"


@dataclass
class Message:
    """Represents a single turn in the conversation (T012)."""
    role: str  # "system" | "user" | "assistant"
    content: str
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = field(default_factory=datetime.now)
    citations: List[Citation] = field(default_factory=list)
    token_count: int = 0
    metadata: Dict = field(default_factory=dict)

    def to_api_format(self) -> dict:
        """Convert to OpenAI message format."""
        return {"role": self.role, "content": self.content}


@dataclass
class Conversation:
    """Represents an ongoing dialogue session (T013)."""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    messages: List[Message] = field(default_factory=list)
    started_at: datetime = field(default_factory=datetime.now)
    total_tokens: int = 0

    def add_message(self, message: Message) -> None:
        """Add a message and update token count."""
        self.messages.append(message)
        self.total_tokens += message.token_count

    def trim_to_budget(self, budget: int) -> None:
        """Remove oldest messages until under token budget.

        Preserves system message if present.
        """
        while self.total_tokens > budget and len(self.messages) > 1:
            # Keep system message (index 0) if present
            if self.messages[0].role == "system":
                if len(self.messages) > 1:
                    removed = self.messages.pop(1)
                    self.total_tokens -= removed.token_count
            else:
                removed = self.messages.pop(0)
                self.total_tokens -= removed.token_count

    def clear(self) -> None:
        """Clear all messages and reset token count."""
        self.messages = []
        self.total_tokens = 0


@dataclass
class RetrievalContext:
    """Represents the chunks retrieved for a query (T014)."""
    query: str
    results: List[RetrievalResult] = field(default_factory=list)
    total_tokens: int = 0
    retrieved_at: datetime = field(default_factory=datetime.now)


@dataclass
class AgentConfig:
    """Configuration for the conversational agent (T015)."""
    model: str = "meta-llama/llama-3.2-3b-instruct:free"
    base_url: str = "https://openrouter.ai/api/v1"
    temperature: float = 0.7
    max_tokens: int = 2048
    system_prompt: str = DEFAULT_SYSTEM_PROMPT
    context_window: int = 8192
    retrieval_top_k: int = 5
    retrieval_threshold: float = 0.3
    # Fallback models if primary is unavailable
    models: List[str] = field(default_factory=lambda: [
        "meta-llama/llama-3.2-3b-instruct:free",
        "mistralai/mistral-7b-instruct:free",
    ])


@dataclass
class AgentState:
    """Runtime state of the agent (T016)."""
    config: AgentConfig
    conversation: Conversation
    total_tokens_used: int = 0
    session_start: datetime = field(default_factory=datetime.now)
    last_retrieval: Optional[RetrievalContext] = None


@dataclass
class ErrorResponse:
    """Standardized error structure for user-facing errors (T017)."""
    error_type: str
    message: str
    user_message: str
    retry_after: Optional[int] = None
    recoverable: bool = True
